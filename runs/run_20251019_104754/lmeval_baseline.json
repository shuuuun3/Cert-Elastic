{
  "results_raw": {
    "results": {
      "gsm8k": {
        "alias": "gsm8k",
        "exact_match,strict-match": 0.0,
        "exact_match_stderr,strict-match": "N/A",
        "exact_match,flexible-extract": 0.5,
        "exact_match_stderr,flexible-extract": "N/A"
      },
      "hendrycks_math": {
        "exact_match,none": 0.0,
        "exact_match_stderr,none": "N/A",
        "alias": "hendrycks_math"
      },
      "hendrycks_math_algebra": {
        "alias": " - hendrycks_math_algebra",
        "exact_match,none": 0.0,
        "exact_match_stderr,none": "N/A"
      },
      "hendrycks_math_counting_and_prob": {
        "alias": " - hendrycks_math_counting_and_prob",
        "exact_match,none": 0.0,
        "exact_match_stderr,none": "N/A"
      },
      "hendrycks_math_geometry": {
        "alias": " - hendrycks_math_geometry",
        "exact_match,none": 0.0,
        "exact_match_stderr,none": "N/A"
      },
      "hendrycks_math_intermediate_algebra": {
        "alias": " - hendrycks_math_intermediate_algebra",
        "exact_match,none": 0.0,
        "exact_match_stderr,none": "N/A"
      },
      "hendrycks_math_num_theory": {
        "alias": " - hendrycks_math_num_theory",
        "exact_match,none": 0.0,
        "exact_match_stderr,none": "N/A"
      },
      "hendrycks_math_prealgebra": {
        "alias": " - hendrycks_math_prealgebra",
        "exact_match,none": 0.0,
        "exact_match_stderr,none": "N/A"
      },
      "hendrycks_math_precalc": {
        "alias": " - hendrycks_math_precalc",
        "exact_match,none": 0.0,
        "exact_match_stderr,none": "N/A"
      },
      "humaneval": {
        "alias": "humaneval",
        "pass@1,create_test": 0.0,
        "pass@1_stderr,create_test": "N/A"
      },
      "mbpp": {
        "alias": "mbpp",
        "pass_at_1,none": 0.0,
        "pass_at_1_stderr,none": "N/A"
      }
    },
    "groups": {
      "hendrycks_math": {
        "exact_match,none": 0.0,
        "exact_match_stderr,none": "N/A",
        "alias": "hendrycks_math"
      }
    },
    "group_subtasks": {
      "gsm8k": [],
      "humaneval": [],
      "mbpp": [],
      "hendrycks_math": [
        "hendrycks_math_algebra",
        "hendrycks_math_counting_and_prob",
        "hendrycks_math_geometry",
        "hendrycks_math_intermediate_algebra",
        "hendrycks_math_num_theory",
        "hendrycks_math_prealgebra",
        "hendrycks_math_precalc"
      ]
    },
    "configs": {
      "gsm8k": {
        "task": "gsm8k",
        "tag": [
          "math_word_problems"
        ],
        "dataset_path": "gsm8k",
        "dataset_name": "main",
        "training_split": "train",
        "test_split": "test",
        "fewshot_split": "train",
        "doc_to_text": "Question: {{question}}\nAnswer:",
        "doc_to_target": "{{answer}}",
        "unsafe_code": false,
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "exact_match",
            "aggregation": "mean",
            "higher_is_better": true,
            "ignore_case": true,
            "ignore_punctuation": false,
            "regexes_to_ignore": [
              ",",
              "\\$",
              "(?s).*#### ",
              "\\.$"
            ]
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "until": [
            "Question:",
            "</s>",
            "<|im_end|>"
          ],
          "do_sample": false,
          "temperature": 0.0
        },
        "repeats": 1,
        "filter_list": [
          {
            "name": "strict-match",
            "filter": [
              {
                "function": "regex",
                "regex_pattern": "#### (\\-?[0-9\\.\\,]+)"
              },
              {
                "function": "take_first"
              }
            ]
          },
          {
            "name": "flexible-extract",
            "filter": [
              {
                "function": "regex",
                "group_select": -1,
                "regex_pattern": "(-?[$0-9.,]{2,})|(-?[0-9]+)"
              },
              {
                "function": "take_first"
              }
            ]
          }
        ],
        "should_decontaminate": false,
        "metadata": {
          "version": 3.0
        }
      },
      "hendrycks_math_algebra": {
        "task": "hendrycks_math_algebra",
        "tag": [
          "math_word_problems"
        ],
        "dataset_path": "EleutherAI/hendrycks_math",
        "dataset_name": "algebra",
        "training_split": "train",
        "test_split": "test",
        "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _process_doc(doc: dict) -> dict:\n        out_doc = {\n            \"problem\": doc[\"problem\"],\n            \"solution\": doc[\"solution\"],\n            \"answer\": remove_boxed(last_boxed_only_string(doc[\"solution\"])),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n",
        "doc_to_text": "Problem: {{problem}}\nAnswer:",
        "doc_to_target": "{{answer}}",
        "unsafe_code": false,
        "process_results": "def process_results(doc: dict, results: List[str]) -> Dict[str, int]:\n    retval = 0\n    indices = [pos for pos, char in enumerate(results[0]) if char == \"$\"]\n    if len(indices) <= 1:\n        answer = results[0]\n    else:\n        answer = results[0][indices[0] + 1 : indices[-1]]\n\n    if is_equiv(answer, remove_boxed(last_boxed_only_string(doc[\"solution\"]))):\n        retval = 1\n\n    results = {\n        \"exact_match\": retval,\n    }\n    return results\n",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "exact_match",
            "aggregation": "mean",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "until": [
            "Problem:"
          ],
          "do_sample": false,
          "temperature": 0.0
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 1.0
        }
      },
      "hendrycks_math_counting_and_prob": {
        "task": "hendrycks_math_counting_and_prob",
        "tag": [
          "math_word_problems"
        ],
        "dataset_path": "EleutherAI/hendrycks_math",
        "dataset_name": "counting_and_probability",
        "training_split": "train",
        "test_split": "test",
        "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _process_doc(doc: dict) -> dict:\n        out_doc = {\n            \"problem\": doc[\"problem\"],\n            \"solution\": doc[\"solution\"],\n            \"answer\": remove_boxed(last_boxed_only_string(doc[\"solution\"])),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n",
        "doc_to_text": "Problem: {{problem}}\nAnswer:",
        "doc_to_target": "{{answer}}",
        "unsafe_code": false,
        "process_results": "def process_results(doc: dict, results: List[str]) -> Dict[str, int]:\n    retval = 0\n    indices = [pos for pos, char in enumerate(results[0]) if char == \"$\"]\n    if len(indices) <= 1:\n        answer = results[0]\n    else:\n        answer = results[0][indices[0] + 1 : indices[-1]]\n\n    if is_equiv(answer, remove_boxed(last_boxed_only_string(doc[\"solution\"]))):\n        retval = 1\n\n    results = {\n        \"exact_match\": retval,\n    }\n    return results\n",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "exact_match",
            "aggregation": "mean",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "until": [
            "Problem:"
          ],
          "do_sample": false,
          "temperature": 0.0
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 1.0
        }
      },
      "hendrycks_math_geometry": {
        "task": "hendrycks_math_geometry",
        "tag": [
          "math_word_problems"
        ],
        "dataset_path": "EleutherAI/hendrycks_math",
        "dataset_name": "geometry",
        "training_split": "train",
        "test_split": "test",
        "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _process_doc(doc: dict) -> dict:\n        out_doc = {\n            \"problem\": doc[\"problem\"],\n            \"solution\": doc[\"solution\"],\n            \"answer\": remove_boxed(last_boxed_only_string(doc[\"solution\"])),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n",
        "doc_to_text": "Problem: {{problem}}\nAnswer:",
        "doc_to_target": "{{answer}}",
        "unsafe_code": false,
        "process_results": "def process_results(doc: dict, results: List[str]) -> Dict[str, int]:\n    retval = 0\n    indices = [pos for pos, char in enumerate(results[0]) if char == \"$\"]\n    if len(indices) <= 1:\n        answer = results[0]\n    else:\n        answer = results[0][indices[0] + 1 : indices[-1]]\n\n    if is_equiv(answer, remove_boxed(last_boxed_only_string(doc[\"solution\"]))):\n        retval = 1\n\n    results = {\n        \"exact_match\": retval,\n    }\n    return results\n",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "exact_match",
            "aggregation": "mean",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "until": [
            "Problem:"
          ],
          "do_sample": false,
          "temperature": 0.0
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 1.0
        }
      },
      "hendrycks_math_intermediate_algebra": {
        "task": "hendrycks_math_intermediate_algebra",
        "tag": [
          "math_word_problems"
        ],
        "dataset_path": "EleutherAI/hendrycks_math",
        "dataset_name": "intermediate_algebra",
        "training_split": "train",
        "test_split": "test",
        "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _process_doc(doc: dict) -> dict:\n        out_doc = {\n            \"problem\": doc[\"problem\"],\n            \"solution\": doc[\"solution\"],\n            \"answer\": remove_boxed(last_boxed_only_string(doc[\"solution\"])),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n",
        "doc_to_text": "Problem: {{problem}}\nAnswer:",
        "doc_to_target": "{{answer}}",
        "unsafe_code": false,
        "process_results": "def process_results(doc: dict, results: List[str]) -> Dict[str, int]:\n    retval = 0\n    indices = [pos for pos, char in enumerate(results[0]) if char == \"$\"]\n    if len(indices) <= 1:\n        answer = results[0]\n    else:\n        answer = results[0][indices[0] + 1 : indices[-1]]\n\n    if is_equiv(answer, remove_boxed(last_boxed_only_string(doc[\"solution\"]))):\n        retval = 1\n\n    results = {\n        \"exact_match\": retval,\n    }\n    return results\n",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "exact_match",
            "aggregation": "mean",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "until": [
            "Problem:"
          ],
          "do_sample": false,
          "temperature": 0.0
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 1.0
        }
      },
      "hendrycks_math_num_theory": {
        "task": "hendrycks_math_num_theory",
        "tag": [
          "math_word_problems"
        ],
        "dataset_path": "EleutherAI/hendrycks_math",
        "dataset_name": "number_theory",
        "training_split": "train",
        "test_split": "test",
        "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _process_doc(doc: dict) -> dict:\n        out_doc = {\n            \"problem\": doc[\"problem\"],\n            \"solution\": doc[\"solution\"],\n            \"answer\": remove_boxed(last_boxed_only_string(doc[\"solution\"])),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n",
        "doc_to_text": "Problem: {{problem}}\nAnswer:",
        "doc_to_target": "{{answer}}",
        "unsafe_code": false,
        "process_results": "def process_results(doc: dict, results: List[str]) -> Dict[str, int]:\n    retval = 0\n    indices = [pos for pos, char in enumerate(results[0]) if char == \"$\"]\n    if len(indices) <= 1:\n        answer = results[0]\n    else:\n        answer = results[0][indices[0] + 1 : indices[-1]]\n\n    if is_equiv(answer, remove_boxed(last_boxed_only_string(doc[\"solution\"]))):\n        retval = 1\n\n    results = {\n        \"exact_match\": retval,\n    }\n    return results\n",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "exact_match",
            "aggregation": "mean",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "until": [
            "Problem:"
          ],
          "do_sample": false,
          "temperature": 0.0
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 1.0
        }
      },
      "hendrycks_math_prealgebra": {
        "task": "hendrycks_math_prealgebra",
        "tag": [
          "math_word_problems"
        ],
        "dataset_path": "EleutherAI/hendrycks_math",
        "dataset_name": "prealgebra",
        "training_split": "train",
        "test_split": "test",
        "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _process_doc(doc: dict) -> dict:\n        out_doc = {\n            \"problem\": doc[\"problem\"],\n            \"solution\": doc[\"solution\"],\n            \"answer\": remove_boxed(last_boxed_only_string(doc[\"solution\"])),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n",
        "doc_to_text": "Problem: {{problem}}\nAnswer:",
        "doc_to_target": "{{answer}}",
        "unsafe_code": false,
        "process_results": "def process_results(doc: dict, results: List[str]) -> Dict[str, int]:\n    retval = 0\n    indices = [pos for pos, char in enumerate(results[0]) if char == \"$\"]\n    if len(indices) <= 1:\n        answer = results[0]\n    else:\n        answer = results[0][indices[0] + 1 : indices[-1]]\n\n    if is_equiv(answer, remove_boxed(last_boxed_only_string(doc[\"solution\"]))):\n        retval = 1\n\n    results = {\n        \"exact_match\": retval,\n    }\n    return results\n",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "exact_match",
            "aggregation": "mean",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "until": [
            "Problem:"
          ],
          "do_sample": false,
          "temperature": 0.0
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 1.0
        }
      },
      "hendrycks_math_precalc": {
        "task": "hendrycks_math_precalc",
        "tag": [
          "math_word_problems"
        ],
        "dataset_path": "EleutherAI/hendrycks_math",
        "dataset_name": "precalculus",
        "training_split": "train",
        "test_split": "test",
        "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _process_doc(doc: dict) -> dict:\n        out_doc = {\n            \"problem\": doc[\"problem\"],\n            \"solution\": doc[\"solution\"],\n            \"answer\": remove_boxed(last_boxed_only_string(doc[\"solution\"])),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n",
        "doc_to_text": "Problem: {{problem}}\nAnswer:",
        "doc_to_target": "{{answer}}",
        "unsafe_code": false,
        "process_results": "def process_results(doc: dict, results: List[str]) -> Dict[str, int]:\n    retval = 0\n    indices = [pos for pos, char in enumerate(results[0]) if char == \"$\"]\n    if len(indices) <= 1:\n        answer = results[0]\n    else:\n        answer = results[0][indices[0] + 1 : indices[-1]]\n\n    if is_equiv(answer, remove_boxed(last_boxed_only_string(doc[\"solution\"]))):\n        retval = 1\n\n    results = {\n        \"exact_match\": retval,\n    }\n    return results\n",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "exact_match",
            "aggregation": "mean",
            "higher_is_better": true
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "until": [
            "Problem:"
          ],
          "do_sample": false,
          "temperature": 0.0
        },
        "repeats": 1,
        "should_decontaminate": false,
        "metadata": {
          "version": 1.0
        }
      },
      "humaneval": {
        "task": "humaneval",
        "dataset_path": "openai/openai_humaneval",
        "test_split": "test",
        "doc_to_text": "{{prompt}}",
        "doc_to_target": "{{test}}\ncheck({{entry_point}})",
        "unsafe_code": true,
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 0,
        "metric_list": [
          {
            "metric": "def pass_at_k(references: list[str], predictions: list[list[str]], k: list[int] = None):\n    global compute_\n    assert k is not None\n    if isinstance(k, int):\n        k = [k]\n    res = compute_.compute(\n        references=references,\n        predictions=predictions,\n        k=k,\n    )\n    return res[0]\n",
            "aggregation": "mean",
            "higher_is_better": true,
            "k": [
              1
            ]
          }
        ],
        "output_type": "generate_until",
        "generation_kwargs": {
          "until": [
            "\nclass",
            "\ndef",
            "\n#",
            "\nif",
            "\nprint"
          ],
          "max_gen_toks": 1024,
          "do_sample": false
        },
        "repeats": 1,
        "filter_list": [
          {
            "name": "create_test",
            "filter": [
              {
                "function": "custom",
                "filter_fn": 