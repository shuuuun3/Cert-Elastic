{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d501a905",
   "metadata": {},
   "source": [
    "# Cert-Elastic on Google Colab\n",
    "\n",
    "このノートブックは、Google Drive にプロジェクトを配置して Colab 上で VS Code と同等の手順で実行できるようにしたものです。GPU を有効化してから実行してください。\n",
    "\n",
    "- 実行対象: `run_evaluate_cert.py`（ログ計測＋要約）\n",
    "- 保存先: Google Drive (`/content/drive/MyDrive/Cert-Elastic`) 配下に成果物を永続化\n",
    "- モデル: 省メモリのためデフォルトで 4bit 量子化を推奨します（Colab T4 / L4 でも動作）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dfcf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file will be replaced by the notebook editor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e126d763",
   "metadata": {},
   "source": [
    "## 1) 必要ライブラリとGPUの確認\n",
    "以下で Python/Pip バージョンと GPU を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac305c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -V\n",
    "!pip -V\n",
    "!nvidia-smi || echo \"No NVIDIA GPU\"\n",
    "\n",
    "import torch, platform\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "print(\"python:\", platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a90db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preflight: GPU/torch/transformers の互換チェックとフォールバック\n",
    "import sys, subprocess, json\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "print('preflight: torch', torch.__version__, 'cuda?', torch.cuda.is_available())\n",
    "print('preflight: transformers', transformers.__version__)\n",
    "\n",
    "# SDPAの可用性チェック（bf16 + A100 前提）\n",
    "need_reinstall = False\n",
    "try:\n",
    "    sdpa_ok = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n",
    "    print('preflight: sdpa available =', sdpa_ok)\n",
    "except Exception:\n",
    "    sdpa_ok = False\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    print('[preflight] CUDA が無効。torch の再インストールを試みます。')\n",
    "    need_reinstall = True\n",
    "\n",
    "if need_reinstall:\n",
    "    # フォールバック: デフォルト index から最新安定版を導入\n",
    "    # （このセルを再実行するときはランタイム再起動が必要な場合があります）\n",
    "    print('[preflight] Reinstalling torch from default index...')\n",
    "    code = subprocess.call([sys.executable, '-m', 'pip', 'install', '-U', 'torch', 'torchvision', 'torchaudio'])\n",
    "    print('[preflight] pip exit code =', code)\n",
    "    import importlib\n",
    "    importlib.invalidate_caches()\n",
    "    import torch as _t\n",
    "    print('after reinstall: torch', _t.__version__, 'cuda?', _t.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dff2d5e",
   "metadata": {},
   "source": [
    "## 2) Google Drive のマウント\n",
    "Drive をマウントして、プロジェクトのルートパスを設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2109ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os, pathlib\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "DRIVE_ROOT = '/content/drive/MyDrive'\n",
    "PROJECT_NAME = 'Cert-Elastic'\n",
    "PROJECT_DIR = f'{DRIVE_ROOT}/{PROJECT_NAME}'\n",
    "print('PROJECT_DIR =', PROJECT_DIR)\n",
    "\n",
    "# HF cache to Drive to persist models between sessions\n",
    "os.environ['HF_HOME'] = f'{DRIVE_ROOT}/.cache/huggingface'\n",
    "os.environ['HF_DATASETS_CACHE'] = f'{DRIVE_ROOT}/.cache/huggingface/datasets'\n",
    "os.environ['TRANSFORMERS_CACHE'] = f'{DRIVE_ROOT}/.cache/huggingface/hub'\n",
    "pathlib.Path(os.environ['HF_HOME']).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc39d519",
   "metadata": {},
   "source": [
    "## 3) Drive 内にプロジェクト用フォルダを作成\n",
    "既存ならスキップされます。出力やログの保存先も合わせて作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8371796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "SUBDIRS = ['src', 'data', 'outputs', 'models', 'logs', 'runs']\n",
    "for sd in SUBDIRS:\n",
    "    os.makedirs(f'{PROJECT_DIR}/{sd}', exist_ok=True)\n",
    "print('created:', [f'{PROJECT_DIR}/{sd}' for sd in SUBDIRS])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd4876a",
   "metadata": {},
   "source": [
    "## 4) リポジトリの取得 or 手元のZIP配置\n",
    "- 公開GitHub: git clone（下の例ではダミーURLなので必要に応じて変更）\n",
    "- 既に PC から Drive に `Cert-Elastic` フォルダをコピー済みならこのセルはスキップしてOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1ebc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# いずれかを利用（既に Drive にコピー済みなら不要）\n",
    "# !git clone --depth 1 https://github.com/yourname/Cert-Elastic.git /content/Cert-Elastic\n",
    "# !unzip -o /content/Cert-Elastic.zip -d /content/\n",
    "# !rsync -a /content/Cert-Elastic/ \"$PROJECT_DIR/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe17329c",
   "metadata": {},
   "source": [
    "## 5) 依存関係のインストール\n",
    "`requirements.txt` と PyTorch をインストールします。Colab GPU は Linux なので `bitsandbytes` も利用可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20b15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"$PROJECT_DIR\"\n",
    "!python -m pip install -U pip wheel setuptools\n",
    "# pip / setuptools 更新直後に IPython の依存警告が出る場合があるため補修\n",
    "!pip install -U \"ipython>=8.12\" \"jedi>=0.16\"\n",
    "# Colab の CUDA に合う公式 index から torch を導入（バージョンは適宜）\n",
    "!pip install --index-url https://download.pytorch.org/whl/cu124 torch torchvision torchaudio\n",
    "\n",
    "# プロジェクトの依存\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# 追加: ベンチ用に lm-eval（EleutherAI/lm-evaluation-harness）や便利ツールも導入\n",
    "!pip install -U lm-eval einops tiktoken\n",
    "\n",
    "import torch\n",
    "print('torch:', torch.__version__, 'cuda available:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a4a4cc",
   "metadata": {},
   "source": [
    "## 6) システム依存のインストール（必要時）\n",
    "このプロジェクトでは通常不要です。必要になった場合のみ以下を利用してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ea7513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例:\n",
    "# !apt-get update -y && apt-get install -y libgl1 libglib2.0-0 graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9c450b",
   "metadata": {},
   "source": [
    "## 7) PYTHONPATH と作業ディレクトリの設定\n",
    "ノートブックからローカルパッケージ `cert_elastic` を import 可能にします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8542378",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"$PROJECT_DIR\"\n",
    "import sys, os\n",
    "if PROJECT_DIR not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_DIR)\n",
    "print(sys.path[:3])\n",
    "\n",
    "# import テスト\n",
    "try:\n",
    "    import cert_elastic\n",
    "    print('cert_elastic imported:', cert_elastic.__file__)\n",
    "except Exception as e:\n",
    "    print('import error:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530ed702",
   "metadata": {},
   "source": [
    "## 8) 環境変数・.env の設定（任意）\n",
    "Hugging Face Hub のトークンなどが必要な場合に設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de092539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 例: os.environ['HF_TOKEN'] = 'hf_XXXXXXXXXXXXXXXX'\n",
    "# from huggingface_hub import login\n",
    "# login(token=os.environ['HF_TOKEN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0bcdd9",
   "metadata": {},
   "source": [
    "## 9) データセットのダウンロード/配置（任意）\n",
    "本プロジェクトではサンプルプロンプトのみなので省略可。外部データが必要になったらここで準備してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd7d37",
   "metadata": {},
   "source": [
    "## 10) テスト（任意）\n",
    "テストがある場合はここで実行します。現状このリポジトリにはテストはありません。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc500fa2",
   "metadata": {},
   "source": [
    "## 11) アプリ/スクリプトの実行\n",
    "`run_evaluate_cert.py` を Colab 向けの低メモリ設定で実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c134fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"$PROJECT_DIR\"\n",
    "\n",
    "# A100向けデフォルト（高性能設定）\n",
    "MODEL_ID = 'mistralai/Mistral-7B-Instruct-v0.3'\n",
    "DTYPE = 'bfloat16'        # A100ならbf16推奨\n",
    "LOAD_IN_4BIT = 0          # 量子化は不要\n",
    "ATNN_IMPL = 'eager'        # 注意: ロギングでは attentions が必要なため eager を使用\n",
    "MAX_NEW_TOKENS = 256\n",
    "EVAL_PROMPTS_N = 50\n",
    "RUN_FAST = 1              # 簡易速度計測をON\n",
    "\n",
    "!python run_evaluate_cert.py \\\n",
    "  --model_id {MODEL_ID} \\\n",
    "  --dtype {DTYPE} \\\n",
    "  --load_in_4bit {LOAD_IN_4BIT} \\\n",
    "  --device_map auto \\\n",
    "  --attn_impl {ATNN_IMPL} \\\n",
    "  --max_new_tokens {MAX_NEW_TOKENS} \\\n",
    "  --eval_prompts_n {EVAL_PROMPTS_N} \\\n",
    "  --run_fast {RUN_FAST} \\\n",
    "  --out_dir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acf0820",
   "metadata": {},
   "source": [
    "## 12) 実行結果の保存とDriveへの永続化\n",
    "`runs/` 以下に生成された最新の run ディレクトリを参照し、主要ファイルを表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9356a0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, glob, os\n",
    "from pathlib import Path\n",
    "\n",
    "%cd \"$PROJECT_DIR\"\n",
    "run_dirs = sorted(glob.glob('runs/run_*'))\n",
    "print('runs found:', run_dirs[-3:])\n",
    "if run_dirs:\n",
    "    latest = run_dirs[-1]\n",
    "    print('latest run:', latest)\n",
    "    for f in ['config.eval.json','results.logging.json','summary.json','cert_checks.csv']:\n",
    "        p = Path(latest)/f\n",
    "        if p.exists():\n",
    "            print(f'--- {p} (head) ---')\n",
    "            if p.suffix == '.json':\n",
    "                print(json.dumps(json.loads(p.read_text()) if p.read_text() else {}, ensure_ascii=False)[:1000])\n",
    "            else:\n",
    "                print('\\n'.join(p.read_text().splitlines()[:10]))\n",
    "        else:\n",
    "            print(f'{p} not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a34c54",
   "metadata": {},
   "source": [
    "## 13) セッション再開用の短縮セル\n",
    "再接続時は以下のみ実行すればすぐ再開できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed09418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os, sys\n",
    "\n",
    "drive.mount('/content/drive', force_remount=False)\n",
    "DRIVE_ROOT = '/content/drive/MyDrive'\n",
    "PROJECT_NAME = 'Cert-Elastic'\n",
    "PROJECT_DIR = f'{DRIVE_ROOT}/{PROJECT_NAME}'\n",
    "%cd \"$PROJECT_DIR\"\n",
    "if PROJECT_DIR not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_DIR)\n",
    "\n",
    "# ここからすぐ 11) を実行可能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fc57d9",
   "metadata": {},
   "source": [
    "## 14) lm-eval-harness で複数データセット評価\n",
    "A100推奨。HumanEval/MBPP はコード実行を伴うため安全確認を自動で許可しています（ノート上で完結）。\n",
    "- 対応エイリアス: gsm8k, humaneval, mbpp, hendrycks_math\n",
    "- time削減のため limit を小さめに調整可能（厳密評価なら外す）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8714e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"$PROJECT_DIR\"\n",
    "\n",
    "MODEL_ID = 'mistralai/Mistral-7B-Instruct-v0.3'\n",
    "DTYPE = 'bfloat16'   # A100向け\n",
    "ATNN_IMPL = 'sdpa'\n",
    "EPSILON = 0.02\n",
    "ALPHA = 0.5\n",
    "BETA = 2.0\n",
    "TASKS = 'gsm8k,humaneval,mbpp,hendrycks_math'\n",
    "FEWSHOT = 0\n",
    "LIMIT = 0   # 0 or None で全件（A100で本評価）。時間短縮は 100 など。\n",
    "\n",
    "!python -m bench.run_lmeval_cert \\\n",
    "  --model_id {MODEL_ID} \\\n",
    "  --dtype {DTYPE} \\\n",
    "  --attn_impl {ATNN_IMPL} \\\n",
    "  --epsilon {EPSILON} \\\n",
    "  --alpha {ALPHA} \\\n",
    "  --beta {BETA} \\\n",
    "  --tasks {TASKS} \\\n",
    "  --fewshot {FEWSHOT} \\\n",
    "  --limit {LIMIT} \\\n",
    "  --out_dir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bd5697",
   "metadata": {},
   "source": [
    "## 15) 論文風スクリプトで Throughput/Acc をまとめて計測\n",
    "手軽に GSM8K / MATH / HumanEval / MBPP を擬似的に一気に回し、`runs/results.certelastic.paperstyle.json` を作ります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5b5951",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"$PROJECT_DIR\"\n",
    "\n",
    "MODEL_ID = 'mistralai/Mistral-7B-Instruct-v0.3'\n",
    "DTYPE = 'bfloat16'\n",
    "ATNN_IMPL = 'sdpa'\n",
    "EPSILON = 0.02\n",
    "ALPHA = 0.5\n",
    "BETA = 2.0\n",
    "TASKS = 'gsm8k,math,humaneval,mbpp'\n",
    "N_ITEMS = 512     # 本評価\n",
    "GEN_LEN = 512\n",
    "TEMP = 0.0\n",
    "TOP_P = 1.0\n",
    "TOP_K = 0\n",
    "\n",
    "!python -m bench.run_certelastic_paperstyle \\\n",
    "  --model_id {MODEL_ID} \\\n",
    "  --dtype {DTYPE} \\\n",
    "  --attn_impl {ATNN_IMPL} \\\n",
    "  --epsilon {EPSILON} \\\n",
    "  --alpha {ALPHA} \\\n",
    "  --beta {BETA} \\\n",
    "  --tasks {TASKS} \\\n",
    "  --n_items {N_ITEMS} \\\n",
    "  --gen_len {GEN_LEN} \\\n",
    "  --temperature {TEMP} \\\n",
    "  --top_p {TOP_P} \\\n",
    "  --top_k {TOP_K} \\\n",
    "  --out runs/results.certelastic.paperstyle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4acbea6",
   "metadata": {},
   "source": [
    "## 16) 表・図の生成（オプション）\n",
    "`configs/paper_tables.template.yaml` と、上で作成された `runs/results.certelastic.paperstyle.json` を組み合わせて図表を作ります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"$PROJECT_DIR\"\n",
    "\n",
    "PAPER_YAML = 'configs/paper_tables.template.yaml'\n",
    "OURS_JSON = 'runs/results.certelastic.paperstyle.json'\n",
    "OUT_DIR = 'runs/figs'\n",
    "\n",
    "!python viz/make_tables_and_plots.py \\\n",
    "  --paper_template {PAPER_YAML} \\\n",
    "  --our_results {OURS_JSON} \\\n",
    "  --out_dir {OUT_DIR}\n",
    "\n",
    "import os\n",
    "print('figures saved to', os.path.abspath(OUT_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a459554c",
   "metadata": {},
   "source": [
    "## 17) 大規模データセットを事前ダウンロード（キャッシュ永続化）\n",
    "長時間評価の前に `datasets` をローカルキャッシュ（Drive）へプリフェッチしておくと、実行が安定・高速化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae26e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# HuggingFace datasets を事前ダウンロード\n",
    "from datasets import load_dataset\n",
    "\n",
    "# GSM8K（train/test）\n",
    "_ = load_dataset('gsm8k', 'main')\n",
    "# Hendrycks MATH（全カテゴリをプリフェッチ）\n",
    "for _cfg in ['algebra','counting_and_probability','geometry','intermediate_algebra','number_theory','prealgebra','precalculus']:\n",
    "    try:\n",
    "        _ = load_dataset('hendrycks/competition_math', _cfg)\n",
    "    except Exception:\n",
    "        try:\n",
    "            _ = load_dataset('competition_math', _cfg)\n",
    "        except Exception as e:\n",
    "            print('[warn] MATH prefetch failed for', _cfg, ':', e)\n",
    "# HumanEval\n",
    "_ = load_dataset('openai_humaneval')\n",
    "# MBPP（sanitized）\n",
    "_ = load_dataset('mbpp', 'sanitized')\n",
    "\n",
    "print('datasets cached under:', os.environ.get('HF_DATASETS_CACHE', '~/.cache/huggingface/datasets'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96447a9",
   "metadata": {},
   "source": [
    "## 18) クイック・サニティチェック（5分以内）\n",
    "A100 課金前に、パイプライン全体が動くか最小構成で検証します。モデル/依存/データセット/Cert-Elastic の一通りを通します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722a4d78",
   "metadata": {},
   "source": [
    "以下の3ステップを順に実行してください（5分以内の煙テスト）。\n",
    "- 基礎評価を最小設定で実行\n",
    "- lm-eval を limit=5 で極小実行（gsm8k, hendrycks_math）\n",
    "- 論文風まとめを極小実行（n_items=8, gen_len=64）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5418265",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"$PROJECT_DIR\"\n",
    "\n",
    "# 1) 最小の基礎評価（短縮）\n",
    "!python run_evaluate_cert.py \\\n",
    "  --model_id mistralai/Mistral-7B-Instruct-v0.3 \\\n",
    "  --dtype bfloat16 \\\n",
    "  --load_in_4bit 0 \\\n",
    "  --device_map auto \\\n",
    "  --attn_impl eager \\\n",
    "  --max_new_tokens 32 \\\n",
    "  --eval_prompts_n 3 \\\n",
    "  --run_fast 1 \\\n",
    "  --out_dir runs\n",
    "\n",
    "# 2) lm-eval を極小サイズで煙テスト（こちらは sdpa のままでOK）\n",
    "!python -m bench.run_lmeval_cert \\\n",
    "  --model_id mistralai/Mistral-7B-Instruct-v0.3 \\\n",
    "  --dtype bfloat16 \\\n",
    "  --attn_impl sdpa \\\n",
    "  --epsilon 0.02 \\\n",
    "  --alpha 0.5 \\\n",
    "  --beta 2.0 \\\n",
    "  --tasks gsm8k,hendrycks_math \\\n",
    "  --fewshot 0 \\\n",
    "  --limit 5 \\\n",
    "  --out_dir runs\n",
    "\n",
    "# 3) 論文風まとめの極小版（こちらも sdpa でOK）\n",
    "!python -m bench.run_certelastic_paperstyle \\\n",
    "  --model_id mistralai/Mistral-7B-Instruct-v0.3 \\\n",
    "  --dtype bfloat16 \\\n",
    "  --attn_impl sdpa \\\n",
    "  --epsilon 0.02 \\\n",
    "  --alpha 0.5 \\\n",
    "  --beta 2.0 \\\n",
    "  --tasks gsm8k,math \\\n",
    "  --n_items 8 \\\n",
    "  --gen_len 64 \\\n",
    "  --temperature 0.0 \\\n",
    "  --top_p 1.0 \\\n",
    "  --top_k 0 \\\n",
    "  --out runs/results.certelastic.paperstyle.json\n",
    "\n",
    "print('Quick sanity done. Check latest runs/ directory.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd2280d",
   "metadata": {},
   "source": [
    "### 18.1) サニティ結果のざっと確認\n",
    "最新の `runs/run_*` から主要ファイルの存在と先頭をチェックして、パイプラインの通過を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfc531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"$PROJECT_DIR\"\n",
    "import json, glob\n",
    "from pathlib import Path\n",
    "\n",
    "run_dirs = sorted(glob.glob('runs/run_*'))\n",
    "print('runs found:', run_dirs[-3:])\n",
    "if run_dirs:\n",
    "    latest = run_dirs[-1]\n",
    "    print('latest:', latest)\n",
    "    for f in ['config.eval.json','results.logging.json','summary.json','cert_checks.csv','lmeval_baseline.json','lmeval_cert.json','results.certelastic.paperstyle.json']:\n",
    "        p = Path(latest)/f\n",
    "        if p.exists():\n",
    "            print(f'--- {p} (head) ---')\n",
    "            if p.suffix == '.json':\n",
    "                try:\n",
    "                    print(json.dumps(json.loads(p.read_text()) if p.read_text() else {}, ensure_ascii=False)[:800])\n",
    "                except Exception:\n",
    "                    print(p.read_text()[:800])\n",
    "            else:\n",
    "                print('\\n'.join(p.read_text().splitlines()[:10]))\n",
    "        else:\n",
    "            print(f'{p} not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc90154",
   "metadata": {},
   "source": [
    "## 19) 全セル順実行（夜間バッチ用）\n",
    "ボタン一つで上から順に主要セルを実行します。Colab のセッション切れを考慮して、適宜 Drive キャッシュを活用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834d8474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab には notebook 内セルを順次トリガーする公式APIがないため、\n",
    "# 主要処理を関数化して順に呼ぶ“擬似一括実行”を用意します。\n",
    "# ここでは、依存インストール済み前提で、(17)->(14)->(15)->(16) の順を走らせます。\n",
    "\n",
    "%cd \"$PROJECT_DIR\"\n",
    "\n",
    "import os, json, sys, subprocess\n",
    "\n",
    "steps = [\n",
    "    [sys.executable, '-c', 'from datasets import load_dataset;\\n'\n",
    "     \"load_dataset('gsm8k','main'); load_dataset('hendrycks/competition_math'); \"\n",
    "     \"load_dataset('openai_humaneval'); load_dataset('mbpp','sanitized'); print('prefetched')\"],\n",
    "    [sys.executable, '-m', 'bench.run_lmeval_cert',\n",
    "     '--model_id','mistralai/Mistral-7B-Instruct-v0.3',\n",
    "     '--dtype','bfloat16','--attn_impl','sdpa',\n",
    "     '--epsilon','0.02','--alpha','0.5','--beta','2.0',\n",
    "     '--tasks','gsm8k,humaneval,mbpp,hendrycks_math',\n",
    "     '--fewshot','0','--limit','0','--out_dir','runs'],\n",
    "    [sys.executable, '-m', 'bench.run_certelastic_paperstyle',\n",
    "     '--model_id','mistralai/Mistral-7B-Instruct-v0.3',\n",
    "     '--dtype','bfloat16','--attn_impl','sdpa',\n",
    "     '--epsilon','0.02','--alpha','0.5','--beta','2.0',\n",
    "     '--tasks','gsm8k,math,humaneval,mbpp',\n",
    "     '--n_items','512','--gen_len','512',\n",
    "     '--temperature','0.0','--top_p','1.0','--top_k','0',\n",
    "     '--out','runs/results.certelastic.paperstyle.json'],\n",
    "    [sys.executable, 'viz/make_tables_and_plots.py',\n",
    "     '--paper_template','configs/paper_tables.template.yaml',\n",
    "     '--our_results','runs/results.certelastic.paperstyle.json',\n",
    "     '--out_dir','runs/figs']\n",
    "]\n",
    "\n",
    "for i, cmd in enumerate(steps, 1):\n",
    "    print(f'\\n[batch] step {i}/{len(steps)} ->', ' '.join(cmd[:6]), '...')\n",
    "    try:\n",
    "        subprocess.run(cmd, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f'[batch] step {i} failed:', e)\n",
    "        break\n",
    "else:\n",
    "    print('[batch] all steps completed')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
